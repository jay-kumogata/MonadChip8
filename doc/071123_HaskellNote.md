## 関数型言語Haskell研究記

### 2007-11-23

P.ドラッカーの本に，面白いことが書いてあります．350年前のモダン主義はデカルト的な考え方です．デカルトの世界では，全ては等式でつながれて自由に移項できます．これに対して，ポストモダンの世界では，いろいろなことは非可逆で，移項はできません．

この記述を見て，Haskellは，すべてを等式（定義）で書きます．数学のように．再帰的な定義を使うことで，物事をスマートに解決できます．つまり，P.ドラッカー風にいうと，モダンの世界はHaskellに向いていると言えるでしょう．

それに対して，ポストモダンの世界では，すべてが不可逆です．つまり，入出力が，非同期になるようなシステムは，（すべての入出力を記憶する以外は）可逆にはなり得ません．システムが十分に複雑であれば，これは，ほとんど不可逆と考えても，差支えないでしょう．

こういった問題を解決するために，Haskellでは，モナドという仕組みを用意しています．Lispだと，prognみたいなものです．これによって，副作用というか，シーケンシャルな動きも書けるようになります．というように考えると，Haskell（関数型プログラミング）はモダンで，ポストモダンに対応するには，モナドが必要ということでしょうか．

### 2008-01-04

年末は絶望的な忙しさで，全く時間がとれませんでしたが，年始にかけ，少し時間がとれたので，Haskell企画について考えてみました．
そして，「まず簡単なCHIP8エミュレータをHaskellで書いてみよう」ということにしました．
ネット上の情報を参考にして，InfoChip8を移植していくことにしました．

- 進捗状況
  - 2007/12/27
    - データ型CPU，関数_CPU_Initを定義
  - 2008/1/3
    - 関数_CPU_Read，_CPU_Writeを定義
  - 2008/1/4
    - 関数_CPU_Step(00EE命令)を定義
- 参考
  - [[Haskell][CPU]6502 emulator](http://d.hatena.ne.jp/tanakh/20040810)

### 2010-02-25

以下論文について，つぶやいたことのまとめです．

- [Runtime Support for Multicore Haskell](https://simonmar.github.io/bib/papers/multicore-ghc.pdf)

#### あらまし

副作用がない純粋な関数型言語は，並列処理に有効なはずです．
これまで，いろいろな論文がアイディアを論じてきましたが，この論文では，GHCに実装して，複雑な設計上のトレードオフを乗り越えることができました．

#### 1 はじめに　

(最初にHaskellでの並列化機構のおさらいがあります．)

- 1996年 明示的なスレッドベースの並列性
- 1998年 半明示的な(semi-explict)決定論的な並列性
- 2009年 データパラレル

この論文では，半明示的な並列性に注目します．

完全に暗示的な並列性は，遠い目標です．
最近では，2007年にHarrisとSinghが挑戦(Feedback-directed implicit parallelismのこと)しました．
それに対して，半明示的なGpHプログラミングモデルは，とても有効でした(1999, 2003年)．

既存のプログラムに対して，どのように並列化するか，という知識をもったプログラマが，小さな変更を加えて，マルチコアで高速に実行させるということなことが，筆者達のゴールです．
GHC6.10での半明示的な実装を徹底的に調査することを着手しました．
以下のような貢献がありました．

- (1) GHCの並列ランタイムの完全な記述(4章)を与えて，その後の章でそれを進化させた．大きな制約は，逐次的なコードの実行速度に対して，わずかに及ばなかったことである(訳注: 逐次的なコードよりも遅くなるケースがあったという意味か？)
- (2) いくつかの設計上の選択を議論．spark分散，スケジューリング，メモリ管理(5,7章)．並列ゴミ集め(6章)，サンク相互排他の実装(8章)，負荷分散，スレッドマイグレーション(9章)
- (3) 主に実装に注目したが，プログラミングモデルにも言及
- (4) プロファイルツール実装(10章)

結論的には，図1に示した通りです．
おおむね向上し，いくつかは劇的に向上しています．
一方，性能が下がってしまっているものもあります．

#### 4 背景: GHCランタイム　

Haskellスレッドは，それぞれ有限サイズのスタックを持っています(これは，ヒープに割り付けられます)．
そのスタックといっしょに，スレッドの状態は，スレッド状態オブジェクト(TSO:thread state object)に保持されます．

4.1 基本セットアップ　

TSOのサイズは，15ワード+スタックサイズで，Haskellスレッドの全状態を構成します．
Haskellスレッドは，一連のOSのスレッド(ワーカースレッド)で実行されます．
物理CPUに対して，ほぼ1スレッド(大まかにいうと)です．

でも，厳密に言うと，瞬間瞬間では，どのワーカースレッドが割りついてるか，変わります(これは，4.2節で，もう少し説明します)．
ワーカースレッドは変わるかもしれないので，CPU毎に，厳密に1個の HEC(Haskell Execution Context: Haskell実行コンテキスト)を維持することにしました．

HECは，以下を含んでいます．

- (1) 現在，その能力を発揮しているワーカースレッドを記録している所有者フィールド(ロックで保護)　
  - →4.2節でなんでそんなややこしいことしているかを説明します
- (2) 他のHECからのリクエストを含むメッセージキュー　
  - →例えば，「スレッドTを起動してくださいね」とかそんなメッセージが届きます
- (3) 実行準備できているスレッドの実行キュー
- (4) 割付領域(6章で説明)　
  - →HEC間で共有できるヒープがひとつありますが，HECはローカル割付領域に割りつけられます
- (5) GC記憶領域(6.2節)
- (6) スパーク(spark)プール　
  - →par a bが実行されると，そのたびに，サンクaが(現行HECの)スパークプールに追加されます
  - →このサンクのことを，「スパーク」と読びます　
  - →訳注: 全然分かんないかもしれないですが，[サンク(thunk)](http://www.haskell.org/haskellwiki/Thunk)というのは，これから評価される値のことです
- (7) 空いているワーカースレッドのプール，TSOの外部コールプール(4.2節)

4.2　外部コール

getCharなんかようなCプロシージャを，Haskellスレッドが呼び出すことを，外部コールと呼びます．

訳注: あまり重要そうなことが書いてないので，読み飛ばしました．

#### 5 より高速なスパーク

ここは，この論文の肝かもしません．
**GHCの実装(レイヤの下の方)を書き換えて，性能が多少良くなった**というのが，この論文の主張点です．

5.1 スパーク共有

GHC6.10.1は，各HEC毎に，私的なスパークプールを持っています．
動いているHaskellスレッド間で，各HECは，スパークプールにスパークがあるか確認します．
もしあったら，空いてるHECがあるか確認します(→アトミックな命令が必要でない軽い処理です)．
もし空いてたら，一時的にその遠隔のHECの所有権をとって，スパークをスパークプールにいれます．

訳注: 要は，暇そうなHEC(つまり，物理CPU)がいたら，その物理CPUにお仕事をお願いするということだと思います．

スパーク分散をより軽く，非同期にやるために，限定work-stealingキュー(定訳なし)を使って，実装し直しました．
限定work-stealingキューは，ロックフリーなデータ構造で，魅力的な特徴を持ってます．
つまりは，キューの持ち主は，非同期でプッシュとポップができます．
その一方で，その他のスレッドは，そのキューの最後を「盗む」ことができ，アトミックな命令をひとつだけ起こすことができます．
キューがほとんど空であれば，ポップしたスレッドと盗んだスレッド間の競合がなく，アトミックな命令の起動できます．

訳注: 空いてる時には，結構うまくいくってことだと思います．
訳注: 限定work-stealingキューについて，少し調べたことを書きます．
「[CLRでのスレッド管理](http://bit.ly/b1nF4E)」にあるように，CLRのスレッドモデルでも，work-stealingキューを使っている模様です．
「JVMではどうなだろう」とか思います．

さて，次が結構おもしろいです．
すでにキューが満杯になっている場合の処理ですが，どっちのスパークを捨てるかって話です．
新しい方か，古い方か．
現在のGHC実装は，新しいスパークを捨てます．
なんでそうなっているかは，この論文ではこれ以上調べません．

訳注: なにが言いたいのか不明です．

5.2　動かすスパークを選ぶ

スパークプールのために，work-stealingキューを使っているので，stealingスレッドは，プールの中の一番古いスパークをとります．
でも，スパークプールを持っているHECは，2つの戦略があります．
つまり，一番新しいスパークをとるか(LIFO: Last In First Out)か，一番古いスパークをとるか(FIFO: First In First Out)です．
最古スパークをとるとアトミックな命令が必要ですが，最新スパークでは不要です．

訳注: この意味分かる方がいれば教えてください．

図4は，FIFOからLIFOに変えた場合の効果を示してます．
でも，結果は，悪くなっています．
つまりは，古いスパークは，「より大きい」って傾向があるってことです．

### 2010-02-26

この論文(*1)は，implicit parallelism(つまり，ソースコードに記載されていない並列性)を抽出して，高速化する手法について論じています．
特に，実行時のプロファイルを使って，並列化できる箇所を特定することが特徴です．

(*1) (2021-10-10) どの論文かは現在調査中です．

#### はじめに

原理的には，Haskellは，マルチコアに適しているはずなのですが，実際には，いくつの課題にぶつかった模様です．

- 1 プログラムにより，実際に使える並列性の量が異なります
- 2 仮に十分な並列性があったとしても，あまり細かい並列性だとオーバーヘッドの方が大きくなるので，十分粗い粒度がなければならなりません
- 3 遅延評価の言語では，個々の計算がどのぐらい「実際の」仕事に貢献するかが分かりづらいです．不必要な仕事は，性能を劣化させます．例えば，大量のメモリが割り当てられると，余計なガベージコレクションが起動されてしまうかもしれません
- 4 プログラムの一部が純粋であるように見えても，バイナリは副作用を含んでる場合があります(例えば，メモ化)
- 5 言語の中心は純粋かもしれないが，実際に記述されるプログラムは，I/Oを含んでいる可能性があります

この論文では，サンク(thunk)を利用しています．
原理的には，割り当てられたサンクは，どれでも評価できます．

訳注: [サンク(Thunk)](http://www.haskell.org/haskellwiki/Thunk)というのは，まだ評価されていない値のことです．
Haskellは，遅延評価するので，サンクを評価しなければらないようになるまで，評価しません．

_(2021-10-10) 10年以上前に，[Twitter](https://twitter.com/jay_kumogata)につぶやいた内容が発見されたので，[Wiki](https://github.com/jay-kumogata/MonadChip8/wiki/100225_HaskellNote)に転載しました．_
_当時は，CPUのマルチコア化が流行しており，どの言語で扱うといいかを調査していました．_
_その後は，NVIDIA社のGPUが覇権を握り，Pythonから専用ライブラリを利用することが主流になりました．_

以上